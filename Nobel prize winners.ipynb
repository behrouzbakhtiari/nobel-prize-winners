{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import re\n",
    "import math\n",
    "import os.path\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import math\n",
    "from tqdm import tqdm_notebook\n",
    "from os import listdir, path\n",
    "from PIL import Image\n",
    "from shutil import copyfile\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your api key here\n",
    "GOODREADS_API_KEY = 'sMrgsSTFjbGpoqLuG29Yeg'\n",
    "GOODREADS_API_URL = 'https://www.goodreads.com/'\n",
    "en_wiki_page_url = 'https://en.wikipedia.org/wiki/List_of_Nobel_laureates_in_Literature'\n",
    "fa_wiki_page_url = 'https://fa.wikipedia.org/wiki/%D9%81%D9%87%D8%B1%D8%B3%D8%AA_%D8%A8%D8%B1%D9%86%D8%AF%DA%AF%D8%A7%D9%86_%D8%AC%D8%A7%DB%8C%D8%B2%D9%87_%D9%86%D9%88%D8%A8%D9%84_%D8%A7%D8%AF%D8%A8%DB%8C%D8%A7%D8%AA'\n",
    "iranketab_url = 'https://www.iranketab.ir'\n",
    "authors_file_path = 'data/authors.csv'\n",
    "orginal_books_dir = 'data/orginal_books/'\n",
    "orginal_books_file_path = 'data/orginal-books.csv'\n",
    "persian_books_dir = 'data/persian-books/'\n",
    "books_file_path = 'books.csv'\n",
    "authors_image_path = 'output/images/authors/'\n",
    "books_image_path = 'output/images/books/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_api_request(url):\n",
    "    url = f\"{GOODREADS_API_URL}{url}&key={GOODREADS_API_KEY}\"\n",
    "    req = requests.get(url)\n",
    "    return xmltodict.parse(req.content)['GoodreadsResponse']\n",
    "\n",
    "def get_image(url,height,save_dir,file_name):\n",
    "     image_type = url[len(url)-4:] \n",
    "     save_path = f'{save_dir}{file_name}{image_type}'\n",
    "     if path.isfile(save_path):\n",
    "         return f\"{file_name}{image_type}\"\n",
    "        \n",
    "     image_url = url\n",
    "     image_url_parts = url.split('._')\n",
    "     \n",
    "     if len(image_url_parts) == 2:\n",
    "        image_url = image_url_parts[0] + image_url_parts[1][len(image_url_parts[1])-4:]    \n",
    "     \n",
    "     temp_file = f\"temp{image_type}\"\n",
    "     download_image(image_url,temp_file)\n",
    "\n",
    "     try:\n",
    "         img = Image.open(temp_file)\n",
    "         new_width  = int(height * img.size[0] / img.size[1])\n",
    "         img = img.resize((new_width, height), Image.ANTIALIAS)\n",
    "         img.save(f'{save_dir}{file_name}{image_type}')   \n",
    "     except Exception as e:\n",
    "        if path.isfile(temp_file):\n",
    "            copyfile(temp_file, f'{save_dir}{file_name}.{image_type}')\n",
    "     return f\"{file_name}{image_type}\"\n",
    "\n",
    "def write_to_csv(file_path, data):\n",
    "    with open(file_path, 'w', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter=',')\n",
    "        for j in data:\n",
    "            writer.writerow(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Authors</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search author by name and return author id            \n",
    "def get_author_goodreads_id(name):\n",
    "    # name = quote(name)\n",
    "    response = make_api_request(f\"api/author_url/{name}?\")\n",
    "    return response['author']['@id']\n",
    "\n",
    "\n",
    "# get author by id\n",
    "def get_author_info_from_goodreads(author_id):\n",
    "    response = make_api_request(\n",
    "        f\"author/show/{author_id}.xml?v=2&shelf=read&per_page=5\")\n",
    "    author_data = response['author']\n",
    "    books_ids = []\n",
    "    if not isinstance(author_data['books']['book'], list):\n",
    "        books_ids.append(author_data['books']['book']['id']['#text'])\n",
    "    else:\n",
    "        for book in author_data['books']['book']:\n",
    "            books_ids.append(book['id']['#text'])\n",
    "\n",
    "    author_info = {\n",
    "        'id': author_data['id'],\n",
    "        'name': author_data['name'],\n",
    "        'url': author_data['link'],\n",
    "        'large_image_url': author_data['large_image_url'],\n",
    "        'small_image_url': author_data['small_image_url'],\n",
    "        'image_url': author_data['image_url'],\n",
    "        'fans_count': author_data['fans_count'].get('#text', '0'),\n",
    "        'author_followers_count': author_data['author_followers_count'].get('#text', '0'),\n",
    "        'works_count': author_data['works_count'],\n",
    "        'gender': author_data['gender'],\n",
    "        'hometown': author_data['hometown'],\n",
    "        'born_at': author_data['born_at'],\n",
    "        'died_at': author_data['died_at'],\n",
    "        'about': author_data['about'],\n",
    "        'books_ids': books_ids\n",
    "    }\n",
    "    return author_info\n",
    "\n",
    "#extract author info from wikipedia table columns\n",
    "def get_author_info_from_wikipedia(columns):\n",
    "    image = columns[1].find('img')\n",
    "    image_url = \"\"\n",
    "    if image != None:\n",
    "        image_url = image.attrs['src']\n",
    "\n",
    "    author_name_tag = columns[2].find('a')\n",
    "    name = author_name_tag.text\n",
    "    about_page_url = author_name_tag.attrs['href']\n",
    "\n",
    "    countries_tag = columns[3].find_all('a')\n",
    "    countries = []\n",
    "    for country in countries_tag:\n",
    "        countries.append(country.text)\n",
    "\n",
    "    flags_tgs = columns[3].find_all('img')\n",
    "    countries_flags = []\n",
    "    for flag in flags_tgs:\n",
    "        countries_flags.append(f\"https:{flag.attrs['src']}\")\n",
    "\n",
    "    languages_tag = columns[4].find_all('a')\n",
    "    languages = []\n",
    "    for language in languages_tag:\n",
    "        languages.append(language.text)\n",
    "\n",
    "    citation = columns[5].text\n",
    "    genres = columns[6].text\n",
    "\n",
    "    return {\n",
    "        'name': name,\n",
    "        'image_url': f'https:{image_url}',\n",
    "        'about_page_url': about_page_url,\n",
    "        'countries': countries,\n",
    "        'countries_flags': countries_flags,\n",
    "        'languages': languages,\n",
    "        'citation': citation,\n",
    "        'genres': genres\n",
    "    }\n",
    "\n",
    "\n",
    "# get author data from iranketab site\n",
    "def get_author_info_from_iranketab(year):\n",
    "    req = requests.get(\n",
    "        \"https://www.iranketab.ir/tag/25-nobel-prize-in-literature\")\n",
    "    soup = BeautifulSoup(req.content, \"html.parser\")\n",
    "    years_tag = soup.find_all('span', {\n",
    "                              'style': 'position: absolute;top: 80px;left: 5px;padding: 7px 50px;background-color: #ffffff;z-index: 2;border: 1px solid #ccc;font-size: 20px;'})\n",
    "    for year_tag in years_tag:\n",
    "\n",
    "        if int(year_tag.text.strip()) == int(year):\n",
    "            author_name_tag = year_tag.parent.find(\n",
    "                'p', {'class': 'product-name-title'}).find('a')\n",
    "            href = iranketab_url + author_name_tag.attrs['href']\n",
    "            profile_req = requests.get(href)\n",
    "            profile_soup = BeautifulSoup(profile_req.content, \"html.parser\")\n",
    "            about = profile_soup.find(\n",
    "                'h5', {'style': 'font-size: 15px;line-height: 30px;'}).text.strip()\n",
    "            image_url = iranketab_url + \\\n",
    "                profile_soup.find('img', {'class': 'img-circle'}).attrs['src']\n",
    "\n",
    "            return {\n",
    "                'about': about,\n",
    "                'image_url': image_url,\n",
    "                'page_url': href\n",
    "            }\n",
    "    return None\n",
    "\n",
    "def get_authors():\n",
    "    en_page_response = requests.get(en_wiki_page_url)\n",
    "    soup_en_page = BeautifulSoup(en_page_response.content, \"html.parser\")\n",
    "    en_authors_table = soup_en_page.find(\n",
    "        \"table\", {\"class\": \"wikitable sortable\"})\n",
    "\n",
    "    fa_page_response = requests.get(fa_wiki_page_url)\n",
    "    soup_fa_page = BeautifulSoup(fa_page_response.content, \"html.parser\")\n",
    "    fa_authors_table = soup_fa_page.find(\n",
    "        \"table\", {\"class\": \"wikitable sortable\"})\n",
    "    authors = [\n",
    "        [\n",
    "            'year',\n",
    "            'gr_id',\n",
    "            'wp_en_name',\n",
    "            'wp_en_author_page_url',\n",
    "            'wp_en_countries',\n",
    "            'wp_en_languages',\n",
    "            'wp_en_citation',\n",
    "            'wp_en_genres',\n",
    "            'wp_fa_name',\n",
    "            'wp_fa_author_page_url',\n",
    "            'wp_fa_countries',\n",
    "            'wp_fa_languages',\n",
    "            'wp_fa_citation',\n",
    "            'wp_fa_genres',\n",
    "            'wp_image_url',\n",
    "            'wp_countries_flags',\n",
    "            'gr_image_url',\n",
    "            'gr_author_page_url',\n",
    "            'gr_fans_count',\n",
    "            'gr_author_followers_count',\n",
    "            'gr_works_count',\n",
    "            'gr_gender',\n",
    "            'gr_hometown',\n",
    "            'gr_born_at',\n",
    "            'gr_died_at',\n",
    "            'gr_about',\n",
    "            'gr_books_ids',\n",
    "            'ik_about',\n",
    "            'ik_image_url',\n",
    "            'ik_page_url',\n",
    "            'image_name'\n",
    "        ]\n",
    "    ]\n",
    "    \n",
    "    pbar = tqdm_notebook(total=len(en_authors_table.find_all(\"tr\")))\n",
    "    row = 0\n",
    "    for en_row, fa_row in zip(en_authors_table.find_all(\"tr\"), fa_authors_table.find_all(\"tr\")):\n",
    "        en_columns = en_row.findAll('td')\n",
    "        if(len(en_columns) == 0):\n",
    "            continue\n",
    "\n",
    "        if(len(en_columns) != 7):\n",
    "            continue\n",
    "\n",
    "        fa_columns = fa_row.findAll('td')\n",
    "\n",
    "        year = en_columns[0].text.strip()[0:4]\n",
    "\n",
    "        en_author = get_author_info_from_wikipedia(en_columns)\n",
    "        fa_author = get_author_info_from_wikipedia(fa_columns)\n",
    "\n",
    "        author_id = get_author_goodreads_id(en_author['name'])\n",
    "        goodreads_author_info = get_author_info_from_goodreads(author_id)\n",
    "\n",
    "        iranketab_author_info = get_author_info_from_iranketab(year)\n",
    "        authors.append([\n",
    "            year,\n",
    "            author_id,\n",
    "            en_author['name'],\n",
    "            en_author['about_page_url'],\n",
    "            \",\".join(en_author['countries']),\n",
    "            \",\".join(en_author['languages']),\n",
    "            en_author['citation'],\n",
    "            en_author['genres'],\n",
    "            fa_author['name'],\n",
    "            fa_author['about_page_url'],\n",
    "            \",\".join(fa_author['countries']),\n",
    "            \",\".join(fa_author['languages']),\n",
    "            fa_author['citation'],\n",
    "            fa_author['genres'],\n",
    "            en_author['image_url'],\n",
    "            \",\".join(en_author['countries_flags']),\n",
    "\n",
    "            goodreads_author_info['image_url'],\n",
    "            goodreads_author_info['url'],\n",
    "            goodreads_author_info['fans_count'],\n",
    "            goodreads_author_info['author_followers_count'],\n",
    "            goodreads_author_info['works_count'],\n",
    "            goodreads_author_info['gender'],\n",
    "            goodreads_author_info['hometown'],\n",
    "            goodreads_author_info['born_at'],\n",
    "            goodreads_author_info['died_at'],\n",
    "            goodreads_author_info['about'],\n",
    "            \",\".join(goodreads_author_info['books_ids']),\n",
    "\n",
    "            \"\" if iranketab_author_info == None else iranketab_author_info['about'],\n",
    "            \"\" if iranketab_author_info == None else iranketab_author_info['image_url'],\n",
    "            \"\" if iranketab_author_info == None else iranketab_author_info['page_url'],\n",
    "            \"\"\n",
    "\n",
    "        ])\n",
    "        row = row + 1\n",
    "        pbar.update(1)\n",
    "    return authors\n",
    "\n",
    "def save_auhtor_images():\n",
    "    df = pd.read_csv(authors_file_path)\n",
    "    df.fillna('',inplace=True)\n",
    "    for index in range(len(df)):\n",
    "        image_url = ''\n",
    "        if df.loc[index,'gr_image_url'] != '' and df.loc[index,'gr_image_url'].find('nophoto')<0:\n",
    "            image_url = df.loc[index,'gr_image_url']\n",
    "        elif df.loc[index,'ik_image_url'] != '':\n",
    "            image_url = df.loc[index,'ik_image_url']\n",
    "        else:\n",
    "            image_url = df.loc[index,'wp_image_url'] \n",
    "        df.loc[index,'image_name'] =  get_image(image_url,350, authors_image_path,df.loc[index,'gr_id'])   \n",
    "    df.to_csv(authors_file_path,index=False)                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = get_authors()\n",
    "write_to_csv(authors_file_path,authors)\n",
    "print(\"Downloaded authors info\")\n",
    "save_auhtor_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Authors Books</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get book info from goodreads\n",
    "def get_book_info(author_id, book_id):\n",
    "    book_tree = make_api_request(f\"book/show/{book_id}.xml?\")\n",
    "    info = book_tree['book']\n",
    "    translators = {'id': [], 'name': [], 'average_rating': []}\n",
    "    authors = {'id': [], 'name': [], 'average_rating': []}\n",
    "    if isinstance(info['authors']['author'], list):\n",
    "        for author in info['authors']['author']:\n",
    "            if author['role'] != None and author['role'] == 'Translator':\n",
    "                translators['id'].append(author['id'])\n",
    "                translators['name'].append(author['name'])\n",
    "                translators['average_rating'].append(author['average_rating'])\n",
    "            else:\n",
    "                authors['id'].append(author['id'])\n",
    "                authors['name'].append(author['name'])\n",
    "                authors['average_rating'].append(author['average_rating'])\n",
    "    else:\n",
    "        author = info['authors']['author']\n",
    "        if author['role'] != None and author['role'] == 'Translator':\n",
    "            translators['id'].append(author['id'])\n",
    "            translators['name'].append(author['name'])\n",
    "            translators['average_rating'].append(author['average_rating'])\n",
    "        else:\n",
    "            authors['id'].append(author['id'])\n",
    "            authors['name'].append(author['name'])\n",
    "            authors['average_rating'].append(author['average_rating'])\n",
    "\n",
    "    return {\n",
    "        'id':info['id'],\n",
    "        'author_id': author_id,\n",
    "        'title': info['title'],\n",
    "        'isbn': info['isbn'],\n",
    "        'isbn13': info['isbn13'],\n",
    "        'country_code': info['country_code'],\n",
    "        'image_url': info['image_url'],\n",
    "        'small_image_url': info['small_image_url'],\n",
    "        'publication_year': info['publication_year'],\n",
    "        'publication_month': info['publication_month'],\n",
    "        'publication_day': info['publication_day'],\n",
    "        'language_code': info['language_code'],\n",
    "        'publisher': info['publisher'],\n",
    "        'is_ebook': info['is_ebook'],\n",
    "        'work_id': info['work']['id']['#text'],\n",
    "        'total_editions_count': info['work']['books_count']['#text'],\n",
    "        'total_added_by': info['work']['reviews_count']['#text'],\n",
    "        'total_rating_sum': info['work']['ratings_sum']['#text'],\n",
    "        'total_rating_count': info['work']['ratings_count']['#text'],\n",
    "        'total_text_reviews_count': info['work']['text_reviews_count']['#text'],\n",
    "        'work_rating_dist': info['work']['rating_dist'],\n",
    "        'work_original_publication_year': info['work']['original_publication_year'].get('#text', ''),\n",
    "        'work_original_publication_month': info['work']['original_publication_month'].get('#text', ''),\n",
    "        'work_original_publication_day': info['work']['original_publication_day'].get('#text', ''),\n",
    "        'avg_rating': info['average_rating'],\n",
    "        'ratings_count': info['ratings_count'],\n",
    "        'text_reviews_count': info['text_reviews_count'],\n",
    "        'authors_ids': authors['id'],\n",
    "        'authors_names': authors['name'],\n",
    "        'authors_avg_rating': authors['average_rating'],\n",
    "        'translators_ids': translators['id'],\n",
    "        'translators_names': translators['name'],\n",
    "        'translators_avg_rating': translators['average_rating'],\n",
    "        'description': info['description']\n",
    "    }\n",
    "\n",
    "\n",
    "# get an author's books\n",
    "def get_author_book_list(author_id):\n",
    "    #name = quote(name)\n",
    "    review_tree = make_api_request(f\"author/list/{author_id}?per_page=10000\")\n",
    "    return review_tree['author']\n",
    "\n",
    "def get_books():\n",
    "    df = pd.read_csv(\"authors.csv\")\n",
    "    df['ik_page_url'].fillna('', inplace=True)\n",
    "\n",
    "    year = 0\n",
    "    try:\n",
    "        for i in tqdm_notebook(range(len(df))):\n",
    "            books = [['id', 'author_id', 'title', 'isbn', 'isbn13', 'country_code', 'image_url', 'small_image_url', 'publication_year', 'publication_month', 'publication_day', 'language_code', 'publisher', 'is_ebook', 'work_id', 'total_editions_count', 'total_added_by', 'total_rating_sum', 'total_rating_count', 'total_text_reviews_count',\n",
    "                      'rating_dist', 'original_publication_year', 'original_publication_month', 'original_publication_day', 'average_rating', 'ratings_count', 'text_reviews_count', 'authors_ids', 'authors_names', 'authors_average_rating', 'translators_ids', 'translators_names', 'translators_average_rating', 'description']]\n",
    "\n",
    "            year = df.loc[i, 'year']\n",
    "            if os.path.isfile(f\"{orginal_books_dir}{year}.csv\"):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                for book in get_author_book_list(df.loc[i, 'gr_id'])['books']['book']:\n",
    "\n",
    "                    book_id = book['id']['#text']\n",
    "\n",
    "                    try:\n",
    "                        find = False\n",
    "                        if isinstance(book['authors']['author'], list):\n",
    "                            for author in book['authors']['author']:\n",
    "                                if df.loc[i, 'gr_id'] == author['id']:\n",
    "                                    find = True\n",
    "                        else:\n",
    "                            if int(df.loc[i, 'gr_id']) == int(book['authors']['author']['id']):\n",
    "                                find = True\n",
    "                        if find == False:\n",
    "                            continue\n",
    "                        \n",
    "                        book_info = get_book_info(df.loc[i, 'gr_id'], book_id)\n",
    "                        books.append([\n",
    "                            book_info['id'],\n",
    "                            book_info['author_id'],\n",
    "                            book_info['title'],\n",
    "                            book_info['isbn'],\n",
    "                            book_info['isbn13'],\n",
    "                            book_info['country_code'],\n",
    "                            book_info['image_url'],\n",
    "                            book_info['small_image_url'],\n",
    "                            book_info['publication_year'],\n",
    "                            book_info['publication_month'],\n",
    "                            book_info['publication_day'],\n",
    "                            book_info['language_code'],\n",
    "                            book_info['publisher'],\n",
    "                            book_info['is_ebook'],\n",
    "                            book_info['work_id'],\n",
    "                            book_info['total_editions_count'],\n",
    "                            book_info['total_added_by'],\n",
    "                            book_info['total_rating_sum'],\n",
    "                            book_info['total_rating_count'],\n",
    "                            book_info['total_text_reviews_count'],\n",
    "                            book_info['work_rating_dist'],\n",
    "                            book_info['work_original_publication_year'],\n",
    "                            book_info['work_original_publication_month'],\n",
    "                            book_info['work_original_publication_day'],\n",
    "                            book_info['avg_rating'],\n",
    "                            book_info['ratings_count'],\n",
    "                            book_info['text_reviews_count'],\n",
    "                            book_info['authors_ids'],\n",
    "                            book_info['authors_names'],\n",
    "                            book_info['authors_avg_rating'],\n",
    "                            book_info['translators_ids'],\n",
    "                            book_info['translators_names'],\n",
    "                            book_info['translators_avg_rating'],\n",
    "                            book_info['description']\n",
    "                        ])\n",
    "                        time.sleep(2)\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                write_to_csv(f\"{orginal_books_dir}{year}.csv\", books)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return books\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_books()\n",
    "print(\"downloaded orignal books\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Persian Editions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_persian_editions(author_id, work_id, work_count):\n",
    "    try:\n",
    "        req = requests.get(\n",
    "            f\"{GOODREADS_API_URL}work/editions/{work_id}?per_page={work_count}\")\n",
    "        soup = BeautifulSoup(req.content, 'html.parser')\n",
    "\n",
    "        work_editions = soup.find(\n",
    "            'div', {'class': 'workEditions'})\n",
    "\n",
    "        elementList = work_editions.find_all(\n",
    "            'div', {'class': 'elementList clearFix'})\n",
    "        persian_editons = []\n",
    "        for book in elementList:\n",
    "            persian_edtions = book.findAll(lambda tag:  'Persian' in tag.text)\n",
    "\n",
    "            for edition in persian_edtions:\n",
    "\n",
    "                if not edition.has_attr('class'):\n",
    "                    continue\n",
    "\n",
    "                if edition.attrs['class'][0] != 'editionData':\n",
    "                    continue\n",
    "\n",
    "                rating_div = book.find(lambda tag:  tag.text.strip(\n",
    "                ) == 'Average rating:').parent.findChildren()[1].get_text().strip()\n",
    "                rating_numbers = re.findall('\\d+\\.*\\d*', rating_div)\n",
    "                avg_rating = rating_numbers[0]\n",
    "                rating_count = rating_numbers[1]\n",
    "\n",
    "                book_link = edition.find(\n",
    "                    'a', {'class': 'bookTitle'}).attrs['href']\n",
    "                book_id = re.search(r\"\\d+\", book_link).group(0)\n",
    "\n",
    "                persian_editons.append(get_book_info(author_id, book_id))\n",
    "                time.sleep(4)\n",
    "        return persian_editons\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "\n",
    "def get_persian_books():\n",
    "     for filename in listdir(orginal_books_dir):\n",
    "       \n",
    "        filepath = os.path.join(orginal_books_dir, filename)\n",
    "        if os.path.isfile(f\"{persian_books_dir}persain_books_{filename}.csv\"):\n",
    "            continue\n",
    "        df = pd.read_csv(filepath)\n",
    "        persian_editons = []\n",
    "        for i in tqdm_notebook(range(len(df))):\n",
    "            try:\n",
    "                books = get_persian_editions(\n",
    "                    df.loc[i, \"author_id\"], df.loc[i, \"work_id\"], df.loc[i, \"total_editions_count\"])\n",
    "                if books != None:\n",
    "                    persian_editons = persian_editons + books\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "            # persian_editons = persian_editons + get_persian_editions()\n",
    "\n",
    "        books = [['id', 'author_id', 'title', 'isbn', 'isbn13', 'country_code', 'image_url', 'small_image_url', 'publication_year', 'publication_month', 'publication_day', 'language_code', 'publisher', 'is_ebook', 'work_id', 'total_editions_count', 'total_added_by', 'total_rating_sum', 'total_rating_count', 'total_text_reviews_count',\n",
    "                  'rating_dist', 'original_publication_year', 'original_publication_month', 'original_publication_day', 'average_rating', 'ratings_count', 'text_reviews_count', 'authors_ids', 'authors_names', 'authors_average_rating', 'translators_ids', 'translators_names', 'translators_average_rating', 'description']]\n",
    "        for book_info in persian_editons:\n",
    "            books.append([\n",
    "                book_info['id'],\n",
    "                book_info['author_id'],\n",
    "                book_info['title'],\n",
    "                book_info['isbn'],\n",
    "                book_info['isbn13'],\n",
    "                book_info['country_code'],\n",
    "                book_info['image_url'],\n",
    "                book_info['small_image_url'],\n",
    "                book_info['publication_year'],\n",
    "                book_info['publication_month'],\n",
    "                book_info['publication_day'],\n",
    "                book_info['language_code'],\n",
    "                book_info['publisher'],\n",
    "                book_info['is_ebook'],\n",
    "                book_info['work_id'],\n",
    "                book_info['total_editions_count'],\n",
    "                book_info['total_added_by'],\n",
    "                book_info['total_rating_sum'],\n",
    "                book_info['total_rating_count'],\n",
    "                book_info['total_text_reviews_count'],\n",
    "                book_info['work_rating_dist'],\n",
    "                book_info['work_original_publication_year'],\n",
    "                book_info['work_original_publication_month'],\n",
    "                book_info['work_original_publication_day'],\n",
    "                book_info['avg_rating'],\n",
    "                book_info['ratings_count'],\n",
    "                book_info['text_reviews_count'],\n",
    "                \",\",join(book_info['authors_ids']),\n",
    "                \",\",join(book_info['authors_names']),\n",
    "                \",\",join(book_info['authors_avg_rating']),\n",
    "                \",\",join(book_info['translators_ids']),\n",
    "                \",\",join(book_info['translators_names']),\n",
    "                \",\",join(book_info['translators_avg_rating']),\n",
    "                book_info['description']\n",
    "            ])\n",
    "        write_to_csv(f\"{persian_books_dir}persain_books_{filename}.csv\", books)\n",
    "     print(\"downloaded persian books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_persian_books()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Generate authors page</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conver_to_persian_digits(string):\n",
    "    digits_map = {\n",
    "        \"0\": \"۰\",\n",
    "        \"1\": \"۱\",\n",
    "        \"2\": \"۲\",\n",
    "        \"3\": \"۳\",\n",
    "        \"4\": \"۴\",\n",
    "        \"5\": \"۵\",\n",
    "        \"6\": \"۶\",\n",
    "        \"7\": \"۷\",\n",
    "        \"8\": \"۸\",\n",
    "        \"9\": \"۹\",\n",
    "    }\n",
    "    return \"\".join([digits_map[digit] if digit in digits_map.keys() else digit for digit in str(string)])\n",
    "\n",
    "def download_image(url, path):\n",
    "    req = requests.get(url, stream=True)\n",
    "    with open(path, 'wb') as out_file:\n",
    "        shutil.copyfileobj(req.raw, out_file)\n",
    "        \n",
    "def get_image(url,height,file_name):\n",
    "     image_type = url[len(url)-4:] \n",
    "     save_path = f'{books_image_path}{file_name}{image_type}'\n",
    "     if path.isfile(save_path):\n",
    "         return f\"{file_name}{image_type}\"\n",
    "        \n",
    "     image_url = url\n",
    "     image_url_parts = url.split('._')\n",
    "     \n",
    "     if len(image_url_parts) == 2:\n",
    "        image_url = image_url_parts[0] + image_url_parts[1][len(image_url_parts[1])-4:]    \n",
    "     \n",
    "     temp_file = f\"temp{image_type}\"\n",
    "     download_image(image_url,temp_file)\n",
    "\n",
    "     try:\n",
    "         img = Image.open(temp_file)\n",
    "         new_width  = int(height * img.size[0] / img.size[1])\n",
    "         img = img.resize((new_width, height), Image.ANTIALIAS)\n",
    "         img.save(f'{books_image_path}{file_name}{image_type}')   \n",
    "     except Exception as e:\n",
    "        if path.isfile(temp_file):\n",
    "            copyfile(temp_file, f'{books_image_path}{file_name}.{image_type}')\n",
    "     return f\"{file_name}{image_type}\"\n",
    "    \n",
    "\n",
    "def concatenate_orginal_persian_books():\n",
    "    books = [[\n",
    "        'author_id',\n",
    "        'id',\n",
    "        'work_id',\n",
    "        'org_id',\n",
    "        'org_title',\n",
    "        'org_publisher',\n",
    "        'original_publication_year',\n",
    "        'title',\n",
    "        'isbn',\n",
    "        'isbn13',\n",
    "        'publisher',\n",
    "        'publication_year',\n",
    "        'total_editions_count',\n",
    "        'total_added_by',\n",
    "        'total_rating_sum',\n",
    "        'total_rating_count',\n",
    "        'total_text_reviews_count',\n",
    "        'score_5',\n",
    "        'score_4',\n",
    "        'score_3',\n",
    "        'score_2',\n",
    "        'score_1',\n",
    "        'score_5_pct',\n",
    "        'score_4_pct',\n",
    "        'score_3_pct',\n",
    "        'score_2_pct',\n",
    "        'score_1_pct',        \n",
    "        'average_rating',\n",
    "        'ratings_count',\n",
    "        'text_reviews_count',\n",
    "        'authors_average_rating',\n",
    "        'translators_ids',\n",
    "        'translators_names',\n",
    "        'translators_average_rating',\n",
    "        'description',\n",
    "        'org_image_name',\n",
    "        'image_name'\n",
    "    ]]\n",
    "    for book_file_name in listdir(orginal_books_dir):\n",
    "        en_df = pd.read_csv(path.join(orginal_books_dir, book_file_name))\n",
    "        pr_df = pd.read_csv(\n",
    "            path.join(persian_books_dir, f\"persain_books_{book_file_name}.csv\"))\n",
    "        en_df.fillna('',inplace = True)\n",
    "        pr_df.fillna('',inplace = True)\n",
    "        \n",
    "        if len(pr_df) == 0:\n",
    "            continue\n",
    "\n",
    "        en_df.sort_values(by=['total_added_by','ratings_count'],ascending = (False, False),inplace = True)\n",
    "        for i in range(len(en_df)):\n",
    "            work_id = en_df.loc[i, 'work_id']\n",
    "            work_df = pr_df[pr_df.work_id == work_id]\n",
    "\n",
    "            for index, row in work_df.iterrows():\n",
    "\n",
    "                if not str(row.author_id) in row.authors_ids:\n",
    "                    continue\n",
    "\n",
    "                rating_dist = row['rating_dist'].split('|')\n",
    "                score_5 = int(rating_dist[0].split(':')[1])\n",
    "                score_4 = int(rating_dist[1].split(':')[1])\n",
    "                score_3 = int(rating_dist[2].split(':')[1])\n",
    "                score_2 = int(rating_dist[3].split(':')[1])\n",
    "                score_1 = int(rating_dist[4].split(':')[1])\n",
    "                \n",
    "                score_5_pct = score_4_pct = score_3_pct = score_2_pct = score_1_pct = 0\n",
    "                total_rating_count = score_5 + score_4 + score_3 + score_2 + score_1\n",
    "                if total_rating_count != 0:\n",
    "                    score_5_pct = round(score_5 * 100 / total_rating_count)\n",
    "                    score_4_pct = round(score_4 * 100 / total_rating_count)\n",
    "                    score_3_pct = round(score_3 * 100 / total_rating_count)\n",
    "                    score_2_pct = round(score_2 * 100 / total_rating_count)\n",
    "                    score_1_pct = round(score_1 * 100 / total_rating_count)\n",
    "                \n",
    "                \n",
    "                books.append([\n",
    "                    row['author_id'],\n",
    "                    row['id'],\n",
    "                    row['work_id'],\n",
    "                    en_df.loc[i, 'id'],\n",
    "                    en_df.loc[i, 'title'],\n",
    "                    en_df.loc[i, 'publisher'],\n",
    "                    '' if row['original_publication_year'] == '' else str(row['original_publication_year'])[:4],\n",
    "                    row['title'],\n",
    "                    row['isbn'],\n",
    "                    row['isbn13'],\n",
    "                    row['publisher'],\n",
    "                    '' if row['publication_year'] == '' else str(row['publication_year'])[:4],\n",
    "                    row['total_editions_count'],\n",
    "                    row['total_added_by'],\n",
    "                    row['total_rating_sum'],\n",
    "                    row['total_rating_count'],\n",
    "                    row['total_text_reviews_count'],\n",
    "                    score_5,\n",
    "                    score_4,\n",
    "                    score_3,\n",
    "                    score_2,\n",
    "                    score_1,\n",
    "                    score_5_pct,\n",
    "                    score_4_pct,\n",
    "                    score_3_pct,\n",
    "                    score_2_pct,\n",
    "                    score_1_pct,                    \n",
    "                    row['average_rating'],\n",
    "                    row['ratings_count'],\n",
    "                    row['text_reviews_count'],\n",
    "                    row['authors_average_rating'],\n",
    "                    row['translators_ids'],\n",
    "                    row['translators_names'].replace(\"'\",'').replace('[','').replace(']','').replace('\\\\u200c',' '),\n",
    "                    row['translators_average_rating'],\n",
    "                    row['description'],\n",
    "                    get_image(en_df.loc[i, 'image_url'],350,en_df.loc[i, 'id']),\n",
    "                    get_image(row['image_url'],250,row['id'])\n",
    "                ])\n",
    "    write_to_csv(books_file_path, books)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_orginal_persian_books()\n",
    "print(\"Concatenate orignal and persian books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(score):\n",
    "    score = float(score)\n",
    "    diff = score - math.floor(score)\n",
    "    round_score = score\n",
    "    if diff > 0 and diff <= 0.25:\n",
    "        round_score = math.floor(score) + 0.25\n",
    "    elif diff > 0.25 and diff <= 0.5:\n",
    "        round_score = math.floor(score) + 0.5\n",
    "    elif diff > 0.5 and diff <= 0.75:\n",
    "        round_score = math.floor(score) + 0.75\n",
    "    elif diff >= 0.75:\n",
    "        round_score = int(math.floor(score) + 1)\n",
    "    return round_score\n",
    "\n",
    "\n",
    "def get_template_text(path):\n",
    "    template_text = \"\"\n",
    "    with open(path) as layout:\n",
    "        template_text = layout.read()    \n",
    "    return template_text\n",
    "    \n",
    "\n",
    "def generate_authors_pages():\n",
    "    df = pd.read_csv(authors_file_path)\n",
    "    df.sort_values(by='year',ascending = False,inplace=True)\n",
    "    \n",
    "    df_org_books = pd.read_csv(orginal_books_file_path)\n",
    "    df_books = pd.read_csv(books_file_path)\n",
    "    df_books.fillna('',inplace = True)\n",
    "    df.fillna('',inplace = True)\n",
    "    \n",
    "    author_layout_template = get_template_text(\"templates/author_layout.tmp\")\n",
    "    author_about_layout_template = get_template_text(\"templates/author_about.tmp\")\n",
    "    org_book_layout_template = get_template_text(\"templates/author_org_book.tmp\")\n",
    "    book_layout_template = get_template_text(\"templates/persian_book_box.tmp\")\n",
    "\n",
    "    layout_template = get_template_text(\"templates/layout.tmp\")\n",
    "    box_template = get_template_text(\"templates/box.tmp\")\n",
    "    authors_list_html = ''\n",
    "    \n",
    "    for i in range(len(df) - 1,-1,-1):\n",
    "        box_html = box_template\n",
    "        author_page = author_layout_template\n",
    "        author_about_page = author_about_layout_template\n",
    "\n",
    "        for col in df.columns:\n",
    "            value = str(df.loc[i, col])\n",
    "            if col in ['year','gr_born_at','gr_died_at','']:\n",
    "                value = conver_to_persian_digits(value)\n",
    "                \n",
    "            author_about_page = author_about_page.replace(\"{\"+col+\"}\", value)\n",
    "            box_html = box_html.replace(\"{\"+col+\"}\", value)\n",
    "        \n",
    "        geners = \"\"\n",
    "        for gener in df.loc[i, \"wp_fa_genres\"].split(\"،\"):\n",
    "            geners += f\" <span>{gener}</span>\"\n",
    "        box_html = box_html.replace(\"{genres}\", geners)\n",
    "        box_html = box_html.replace(\"{author_page}\", df.loc[i, 'wp_en_name'].replace(' ','_'))\n",
    "            \n",
    "        org_books_html = \"\"\n",
    "        books = df_books[df_books.author_id == df.loc[i, \"gr_id\"]]\n",
    "        org_books = df_org_books[df_org_books.author_id == df.loc[i, \"gr_id\"]]\n",
    "        total_org_books = org_books[['total_added_by','average_rating','total_rating_count','total_rating_sum']].sum()\n",
    "        \n",
    "        total_readers = int(total_org_books['total_added_by'])\n",
    "        total_books = len(org_books.index)\n",
    "        total_avg_rating = 0\n",
    "        if total_org_books['total_rating_count'] > 0:\n",
    "            total_avg_rating = round(total_org_books['total_rating_sum'] / total_org_books['total_rating_count'],2)\n",
    "        total_rating_count = int(total_org_books['total_rating_count'])\n",
    "        \n",
    "        for org_book_index,org_book in org_books.iterrows():\n",
    "            row = 0\n",
    "            books_box = ''\n",
    "            org_book_html = org_book_layout_template\n",
    "            \n",
    "            if len(books[books.work_id == org_book.work_id]) == 0:\n",
    "                continue\n",
    "           \n",
    "            language = ''\n",
    "            description = ''\n",
    "            for index, book in books[books.work_id == org_book.work_id].iterrows():\n",
    "                if book.description != '':\n",
    "                    language = detect(book.description)\n",
    "                \n",
    "                if language == 'fa':\n",
    "                    if len(book.description ) > len(description):\n",
    "                        description = book.description \n",
    "                        \n",
    "                book_box = book_layout_template\n",
    "                \n",
    "                for col in df_books.columns:\n",
    "                    \n",
    "                    value = book[col]\n",
    "                    if col in ['publication_year','original_publication_year']:\n",
    "                        value = str(value)[:4]\n",
    "                    if col in ['total_added_by','total_rating_count','total_text_reviews_count','ratings_count','text_reviews_count']:\n",
    "                        value = format(value,',d')\n",
    "                    if col in ['score_5','score_4','score_3','score_2','score_1','total_added_by','total_rating_count','total_text_reviews_count','average_rating','ratings_count','text_reviews_count','publication_year','original_publication_year']:\n",
    "                        value = conver_to_persian_digits(str(value))\n",
    "                    \n",
    "                    if row == 0:\n",
    "                        org_book_html = org_book_html.replace(\"{\"+col+\"}\", str(value))\n",
    "                    \n",
    "                    book_box = book_box.replace(\"{\"+col+\"}\", str(value))\n",
    "  \n",
    "               \n",
    "                books_box += book_box\n",
    "                row+=1\n",
    "            \n",
    "            org_book_html = org_book_html.replace(\"{book_description}\",description if description != '' else book.description )            \n",
    "            org_book_html = org_book_html.replace(\"{star_average_rating}\", str(get_score(book.average_rating)))\n",
    "            org_books_html = org_books_html + org_book_html\n",
    "            org_books_html = org_books_html.replace(\"{persian_books}\", books_box)\n",
    "           \n",
    "        \n",
    "\n",
    "\n",
    "        author_about_page = author_about_page.replace('{books_total_rating_count}',conver_to_persian_digits(str(format(total_rating_count,',d')))) \n",
    "        author_about_page = author_about_page.replace('{books_total_added_by}',conver_to_persian_digits(str(format(total_readers,',d'))))  \n",
    "        author_about_page = author_about_page.replace('{star_books_average_rating}',str(get_score(total_avg_rating))) \n",
    "        \n",
    "        \n",
    "        author_page = author_page.replace(\"{author_about}\", author_about_page)\n",
    "        author_page = author_page.replace(\"{books}\", org_books_html)\n",
    "        \n",
    "        \n",
    "            \n",
    "        box_html = box_html.replace('{total_average_rating}',conver_to_persian_digits(str(total_avg_rating))) \n",
    "        box_html = box_html.replace('{star_total_average_rating}',str(get_score(total_avg_rating))) \n",
    "        \n",
    "        box_html = box_html.replace('{total_rating_count}',conver_to_persian_digits(str(format(total_rating_count,',d')))) \n",
    "        box_html = box_html.replace('{total_added_by}',conver_to_persian_digits(str(format(total_readers,',d'))))  \n",
    "        \n",
    "        authors_list_html += box_html\n",
    "        with open(f\"output/{df.loc[i, 'wp_en_name'].replace(' ','_')}.html\", \"w\") as file:\n",
    "            file.write(author_page)\n",
    "    with open(f\"output/index.html\", \"w\") as file:\n",
    "        file.write(layout_template.replace(\"{authors}\", authors_list_html))                  \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Statistics</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_youngest_authors():\n",
    "    df = pd.read_csv(authors_file_path)\n",
    "    df['winning_age'] = df.year - df.gr_born_at.str[:4].astype('int32')\n",
    "    df.sort_values(by=['winning_age', 'year'], inplace=True)\n",
    "    return df[['year', 'gr_id' , 'wp_en_name', 'wp_fa_name', 'winning_age','image_name']][:5]\n",
    "\n",
    "\n",
    "def get_oldest_authors():\n",
    "    df = pd.read_csv(authors_file_path)\n",
    "    df['winning_age'] = df.year - df.gr_born_at.str[:4].astype('int32')\n",
    "    df.sort_values(by=['winning_age', 'year'], inplace=True, ascending=False)\n",
    "    return df[['year', 'wp_en_name', 'wp_fa_name', 'winning_age','image_name']][:5]\n",
    "\n",
    "\n",
    "def get_based_on_decade():\n",
    "    df = pd.read_csv(authors_file_path)\n",
    "    df['decade'] = np.floor((df.year - df.gr_born_at.str[:4].astype('int32')) / 10)\n",
    "    \n",
    "def get_most_popular_authors():\n",
    "    df = pd.read_csv(orginal_books_file_path)\n",
    "    most_popular_authors = df.groupby(['author_id'])['total_added_by'].sum().sort_values(ascending=False)[:10]\n",
    "\n",
    "    df1 = pd.read_csv(authors_file_path)\n",
    "\n",
    "    df_inner = pd.merge(df1, most_popular_authors, left_on='gr_id', right_on='author_id',how = 'inner')\n",
    "    return df_inner[['year','wp_en_name','wp_fa_name','image_name','total_added_by']].sort_values('total_added_by',ascending=False)\n",
    "\n",
    "def get_authors_with_most_reviews():\n",
    "    df = pd.read_csv(orginal_books_file_path)\n",
    "    most_text_reviews = df.groupby(['author_id'])['total_text_reviews_count'].sum().sort_values(ascending=False)[:10]\n",
    "\n",
    "    df1 = pd.read_csv(authors_file_path)\n",
    "\n",
    "    df_inner = pd.merge(df1, most_text_reviews, left_on='gr_id', right_on='author_id',how = 'inner')\n",
    "    return df_inner[['year','wp_en_name','wp_fa_name','image_name','total_text_reviews_count']].sort_values('total_text_reviews_count',ascending=False)\n",
    " \n",
    "def get_most_popular_books():\n",
    "    df = pd.read_csv(orginal_books_file_path)\n",
    "    most_popular_book = df.groupby(['id','title','image_url'], as_index=False)[['author_id','total_added_by']].sum().sort_values(by= ['total_added_by'], ascending=False)[:10]\n",
    "    df1 = pd.read_csv(authors_file_path)\n",
    "    df_inner = pd.merge(df1, most_popular_book, left_on='gr_id', right_on='author_id',how = 'inner')\n",
    "    df_inner.fa_title = ''\n",
    "    persian_books = pd.read_csv(books_file_path)\n",
    "\n",
    "    for index,row in df_inner.iterrows():\n",
    "        df_inner.loc[index,'fa_title'] = persian_books[persian_books.org_id == row.id].sort_values(by='ratings_count',ascending=False)[0:1]['title'].values\n",
    "    return df_inner[['year','wp_en_name','wp_fa_name','image_name','total_added_by','title','image_url','fa_title']].sort_values('total_added_by',ascending=False)\n",
    "\n",
    "def get_books_with_most_reviews():\n",
    "    df = pd.read_csv(orginal_books_file_path)\n",
    "    most_popular_book = df.groupby(['id','title','image_url'], as_index=False)[['author_id','total_text_reviews_count']].sum().sort_values(by= ['total_text_reviews_count'], ascending=False)[:10]\n",
    "    df1 = pd.read_csv(authors_file_path)\n",
    "    df_inner = pd.merge(df1, most_popular_book, left_on='gr_id', right_on='author_id',how = 'inner')\n",
    "    df_inner.fa_title = ''\n",
    "    persian_books = pd.read_csv(books_file_path)\n",
    "\n",
    "    for index,row in df_inner.iterrows():\n",
    "        df_inner.loc[index,'fa_title'] = persian_books[persian_books.org_id == row.id].sort_values(by='ratings_count',ascending=False)[0:1]['title'].values\n",
    "    return df_inner[['year','wp_en_name','wp_fa_name','image_name','total_text_reviews_count','title','image_url','fa_title']].sort_values('total_text_reviews_count',ascending=False)\n",
    "\n",
    "def get_based_on_geners():\n",
    "    df = pd.read_csv(authors_file_path)\n",
    "    authors = []\n",
    "    for index,row in df.iterrows():\n",
    "        genres = row.wp_fa_genres.split('،')\n",
    "        for gener in genres:\n",
    "            authors.append([row.gr_id,gener.strip()])\n",
    "    df = pd.DataFrame(data=authors, columns=[\"author_id\", \"gener\"])      \n",
    "    return df.groupby(['gener'], as_index=False).count().sort_values(by='author_id',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_template_text(path):\n",
    "    template_text = \"\"\n",
    "    with open(path) as layout:\n",
    "        template_text = layout.read()    \n",
    "    return template_text\n",
    "\n",
    "def generate_statistics_page():\n",
    "    list_box_layout = get_template_text(\"templates/listsbox.tmp\")\n",
    "    \n",
    "    df = get_youngest_authors()\n",
    "    rows = \"\"\n",
    "    for index,row in df.iterrows():\n",
    "        row = f\"<tr><td><img src='images/authors/{row.image_name}' alt='{row.wp_fa_name}'/></td><td class='text-right'><a href='{row.wp_en_name.replace(' ','_')}.html'>{row.wp_fa_name}</a></td><td>{conver_to_persian_digits(row.winning_age)} سالگی</td></tr>\"\n",
    "        rows+=row\n",
    "    youngest_authors = list_box_layout\n",
    "    youngest_authors = youngest_authors.replace(\"{title}\",\"جوان‌ترین برندگان نوبل ادبیات\")\n",
    "    youngest_authors = youngest_authors.replace(\"{rows}\",rows)\n",
    "    youngest_authors = youngest_authors.replace(\"{col_count}\",\"6\")\n",
    "    \n",
    "    df = get_oldest_authors()\n",
    "    rows = \"\"\n",
    "    for index,row in df.iterrows():\n",
    "        row = f\"<tr><td><img src='images/authors/{row.image_name}' alt='{row.wp_fa_name}'/></td><td class='text-right'><a href='{row.wp_en_name.replace(' ','_')}.html'>{row.wp_fa_name}</a></td><td>{conver_to_persian_digits(row.winning_age)} سالگی</td></tr>\"\n",
    "        rows+=row\n",
    "    oldest_authors = list_box_layout\n",
    "    oldest_authors = oldest_authors.replace(\"{title}\",\"مسن‌ترین برندگان نوبل ادبیات\")\n",
    "    oldest_authors = oldest_authors.replace(\"{rows}\",rows)\n",
    "   \n",
    "    oldest_authors = oldest_authors.replace(\"{col_count}\",\"6\")\n",
    "    \n",
    "    df = get_most_popular_authors()\n",
    "    rows = \"\"\n",
    "    for index,row in df.iterrows():\n",
    "        row = f\"<tr><td><img src='images/authors/{row.image_name}' alt='{row.wp_fa_name}'/></td><td class='text-right'><a href='{row.wp_en_name.replace(' ','_')}.html'>{row.wp_fa_name}</a></td><td>{conver_to_persian_digits(format(row.total_added_by,',d'))} بار خوانده شده</td></tr>\"\n",
    "        rows+=row\n",
    "    most_popular_authors = list_box_layout\n",
    "    most_popular_authors = most_popular_authors.replace(\"{title}\",\"برندگانی با بیشترین آثار خوانده شده\")\n",
    "    most_popular_authors = most_popular_authors.replace(\"{rows}\",rows)\n",
    "    most_popular_authors = most_popular_authors.replace(\"{col_count}\",\"6\")\n",
    "\n",
    "    df = get_authors_with_most_reviews()\n",
    "    rows = \"\"\n",
    "    for index,row in df.iterrows():\n",
    "        row = f\"<tr><td><img src='images/authors/{row.image_name}' alt='{row.wp_fa_name}'/></td><td class='text-right'><a href='{row.wp_en_name.replace(' ','_')}.html'>{row.wp_fa_name}</a></td><td>{conver_to_persian_digits(format(row.total_text_reviews_count,',d'))} ریویو متنی</td></tr>\"\n",
    "        rows+=row\n",
    "    authors_with_most_reviews = list_box_layout\n",
    "    authors_with_most_reviews = authors_with_most_reviews.replace(\"{title}\",\"برندگانی با بیشترین ریویو متنی در آثار\")\n",
    "    authors_with_most_reviews = authors_with_most_reviews.replace(\"{rows}\",rows)\n",
    "    authors_with_most_reviews = authors_with_most_reviews.replace(\"{col_count}\",\"6\")\n",
    "\n",
    "    df = get_most_popular_books()\n",
    "    rows = \"\"\n",
    "    for index,row in df.iterrows():\n",
    "        row = f\"<tr><td><img src='images/authors/{row.image_name}' alt='{row.wp_fa_name}'/></td><td class='text-right'><a href='{row.wp_en_name.replace(' ','_')}.html'>{row.wp_fa_name}</a></td><td><img src='{row.image_url}'/></td><td class='text-right'>{row.fa_title}</td><td>{conver_to_persian_digits(format(row.total_added_by,',d'))} بار خوانده شده</td></tr>\"\n",
    "        rows+=row\n",
    "    most_popular_books = list_box_layout\n",
    "    most_popular_books = most_popular_books.replace(\"{title}\",\"آثار بیشتر خوانده شده\")\n",
    "    most_popular_books = most_popular_books.replace(\"{rows}\",rows)\n",
    "    most_popular_books = most_popular_books.replace(\"{col_count}\",\"12\")\n",
    "    \n",
    "    df = get_books_with_most_reviews()\n",
    "    rows = \"\"\n",
    "    for index,row in df.iterrows():\n",
    "        row = f\"<tr><td><img src='images/authors/{row.image_name}' alt='{row.wp_fa_name}'/></td><td class='text-right'><a href='{row.wp_en_name.replace(' ','_')}.html'>{row.wp_fa_name}</a></td><td><img src='{row.image_url}'/></td><td class='text-right'>{row.fa_title}</td><td>{conver_to_persian_digits(format(row.total_text_reviews_count,',d'))} ریویو متنی</td></tr>\"\n",
    "        rows+=row\n",
    "    books_with_most_reviews = list_box_layout\n",
    "    books_with_most_reviews = books_with_most_reviews.replace(\"{title}\",\"آثاری با بیشترین ریویو متنی\")\n",
    "    books_with_most_reviews = books_with_most_reviews.replace(\"{rows}\",rows)\n",
    "    books_with_most_reviews = books_with_most_reviews.replace(\"{col_count}\",\"12\")\n",
    "    \n",
    "    df = get_based_on_geners()\n",
    "    rows = \"\"\n",
    "    for index,row in df.iterrows():\n",
    "        row = f\"<tr><td class='text-right'><td class='text-right'>{row.gener}</td><td>{conver_to_persian_digits(format(row.author_id,',d'))} نویسنده</td></tr>\"\n",
    "        rows+=row\n",
    "    geners = list_box_layout\n",
    "    geners = geners.replace(\"{title}\",\"آثاری با بیشترین ریویو متنی\")\n",
    "    geners = geners.replace(\"{rows}\",rows)\n",
    "    geners = geners.replace(\"{col_count}\",\"6\")\n",
    "    \n",
    "    lists = youngest_authors + oldest_authors + most_popular_authors + authors_with_most_reviews + most_popular_books + books_with_most_reviews + geners\n",
    "    statistics_layout = get_template_text(\"templates/statistics_layout.tmp\")\n",
    "    statistics_layout = statistics_layout.replace('{lists}',lists)\n",
    "    with open(f\"output/statistics.html\", \"w\") as file:\n",
    "        file.write(statistics_layout)   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_authors_pages()\n",
    "generate_statistics_page()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
